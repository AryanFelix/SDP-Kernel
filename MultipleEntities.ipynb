{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 69,
            "source": [
                "import xml.etree.ElementTree as ET\r\n",
                "import re\r\n",
                "import spacy\r\n",
                "import scispacy\r\n",
                "import spacy_transformers\r\n",
                "import numpy as np\r\n",
                "import networkx as nx\r\n",
                "\r\n",
                "from sklearn.svm import SVC\r\n",
                "from sklearn.model_selection import GridSearchCV\r\n",
                "from sklearn.pipeline import Pipeline\r\n",
                "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\r\n",
                "from nltk.tag import pos_tag\r\n",
                "from spacy import displacy"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "source": [
                "def stringReplace(object):\r\n",
                "    temp = object.group(0)\r\n",
                "    temp = temp[0] + \" \" + temp[1]\r\n",
                "    return temp"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "source": [
                "def dataPreprocess(root):\r\n",
                "    docs = []\r\n",
                "    entities = []\r\n",
                "    vocabulary = []\r\n",
                "    sentences = []\r\n",
                "    entVals = []\r\n",
                "    yLabel = []\r\n",
                "    entStorages = []\r\n",
                "    for x in root.findall(\"./document/sentence\"):\r\n",
                "        count = 0\r\n",
                "        yCount = 0\r\n",
                "        flag = 0\r\n",
                "        sentence = x.attrib[\"text\"]\r\n",
                "        sentence = re.sub('[a-z]\\(', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[a-z]\\)', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\([a-z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\)[a-z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[a-z]\\/', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\/[a-z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[a-z]\\.', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[a-z]\\,', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[a-z]\\-', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\-[a-z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[A-Z]\\-', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[A-Z]\\(', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[A-Z]\\)', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\([A-Z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\)[A-Z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\-[A-Z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[A-Z]\\/', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\/[A-Z]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[0-9]\\-', stringReplace, sentence)\r\n",
                "        sentence = re.sub('\\-[0-9]', stringReplace, sentence)\r\n",
                "        sentence = re.sub('[0-9]\\(', stringReplace, sentence)\r\n",
                "        temp = sentence\r\n",
                "        entCount = 0\r\n",
                "        entStorage = []\r\n",
                "        pairStorage = []\r\n",
                "        for i in x.findall(\"./entity\"):\r\n",
                "            entCount += 1\r\n",
                "        if entCount < 2:\r\n",
                "            continue\r\n",
                "        for i in x.findall(\"./entity\"):\r\n",
                "            entDraft = i.attrib[\"text\"]\r\n",
                "            entDraft = re.sub('[a-z]\\(', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[a-z]\\)', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\([a-z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\)[a-z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[a-z]\\/', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\/[a-z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[a-z]\\.', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[a-z]\\,', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[a-z]\\-', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\-[a-z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[A-Z]\\-', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[A-Z]\\(', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[A-Z]\\)', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\([A-Z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\)[A-Z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\-[A-Z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[A-Z]\\/', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\/[A-Z]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[0-9]\\-', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('\\-[0-9]', stringReplace, entDraft)\r\n",
                "            entDraft = re.sub('[0-9]\\(', stringReplace, entDraft)\r\n",
                "            if entDraft in entStorage:\r\n",
                "                flag = 1\r\n",
                "            entStorage.append(entDraft)\r\n",
                "        if flag == 1:\r\n",
                "            continue\r\n",
                "        entStorages.append(entStorage)\r\n",
                "        for i in x.findall(\"./pair\"):\r\n",
                "            if (entStorage[int(i.attrib[\"e1\"][-1])] == entStorage[int(i.attrib[\"e2\"][-1])]):\r\n",
                "                continue\r\n",
                "            elif (entStorage[int(i.attrib[\"e2\"][-1])].find(entStorage[int(i.attrib[\"e1\"][-1])]) != -1):\r\n",
                "                continue\r\n",
                "            elif (entStorage[int(i.attrib[\"e1\"][-1])].find(entStorage[int(i.attrib[\"e2\"][-1])]) != -1):\r\n",
                "                continue\r\n",
                "            if i.attrib[\"interaction\"] == \"False\":\r\n",
                "                interVal = 0\r\n",
                "            else:\r\n",
                "                interVal = 1\r\n",
                "            tup = (int(i.attrib[\"e1\"][-1]), int(i.attrib[\"e2\"][-1]), interVal)\r\n",
                "            pairStorage.append(tup)\r\n",
                "        for (a, b, c) in pairStorage:\r\n",
                "            vals = {}\r\n",
                "            ents = {}\r\n",
                "            tempSen = sentence\r\n",
                "            tempSen = tempSen.replace(entStorage[a], \"ENTITY0\")\r\n",
                "            tempSen = tempSen.replace(entStorage[b], \"ENTITY1\")\r\n",
                "            ents[entStorage[a]] = [\"BRAIN_REGION\"]\r\n",
                "            ents[entStorage[b]] = [\"BRAIN_REGION\"]\r\n",
                "            vals[\"ENTITY0\"] = entStorage[a]\r\n",
                "            vals[\"ENTITY1\"] = entStorage[b]\r\n",
                "            yLabel.append(c)\r\n",
                "            docs.append(tempSen)\r\n",
                "            entVals.append(vals)\r\n",
                "            sentences.append(sentence)\r\n",
                "            entities.append(ents)\r\n",
                "    return yLabel, docs, entVals, sentences, entities"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "source": [
                "def shortestPathsCalculator(yLabel, docs, entVals, sentences, entities):\r\n",
                "    shortestPaths = []\r\n",
                "    dependecies = []\r\n",
                "    nums = []\r\n",
                "    _docs = docs\r\n",
                "    for sr, i in enumerate(_docs):\r\n",
                "        # print(i)\r\n",
                "        document = nlp(i)\r\n",
                "        edges = []\r\n",
                "        deps = []\r\n",
                "        for token in document:\r\n",
                "            for child in token.children:\r\n",
                "                edges.append(('{0}'.format(token.lower_), '{0}'.format(child.lower_)))\r\n",
                "                deps.append(('{0}'.format(token.dep_), '{0}'.format(child.dep_)))\r\n",
                "        graph = nx.Graph(edges)\r\n",
                "        entity1 = 'entity0'\r\n",
                "        entity2 = 'entity1'\r\n",
                "        # print(sr)\r\n",
                "        # print(edges)\r\n",
                "        try:\r\n",
                "            path = nx.shortest_path(graph, source=entity1, target=entity2)\r\n",
                "            directions = []\r\n",
                "            dirDeps = []\r\n",
                "            for xi, x in enumerate(edges):\r\n",
                "                for y in range(len(path) - 1):\r\n",
                "                    if path[y] in x:\r\n",
                "                        if path[y] == x[0]:\r\n",
                "                            if path[y + 1] == x[1]:\r\n",
                "                                directions.append(\"->\")\r\n",
                "                                dirDeps.append([deps[xi][0], deps[xi][1]])\r\n",
                "                            else:\r\n",
                "                                continue\r\n",
                "                        else:\r\n",
                "                            if path[y + 1] == x[0]:\r\n",
                "                                directions.append(\"<-\")\r\n",
                "                                dirDeps.append([deps[xi][1], deps[xi][0]])\r\n",
                "                            else:\r\n",
                "                                continue\r\n",
                "                    else:\r\n",
                "                        continue\r\n",
                "            finalPath = []\r\n",
                "            for x in range(len(path)):\r\n",
                "                finalPath.append(path[x])\r\n",
                "                if len(directions) > x:\r\n",
                "                    finalPath.append(directions[x])\r\n",
                "        except nx.NetworkXNoPath:\r\n",
                "            del yLabel[sr]\r\n",
                "            del docs[sr]\r\n",
                "            del sentences[sr]\r\n",
                "            del entVals[sr]\r\n",
                "            del entities[sr]\r\n",
                "            continue   \r\n",
                "        # print(path)\r\n",
                "        nums.append(sr)\r\n",
                "        shortestPaths.append(finalPath)\r\n",
                "        dependecies.append(dirDeps)\r\n",
                "    print(len(nums), len(shortestPaths), len(dependecies), len(yLabel), len(docs), len(sentences), len(entVals), len(entities))\r\n",
                "    return shortestPaths, dependecies"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "source": [
                "def entityLabels(sentences, entities):\r\n",
                "    for sr, x in enumerate(sentences):\r\n",
                "        document = nlp(x)\r\n",
                "        for d in document.ents:\r\n",
                "            for i in entities[sr].keys():\r\n",
                "                if d.text in i:\r\n",
                "                    if d.label_ not in entities[sr][i]:\r\n",
                "                        entities[sr][i].append(d.label_)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "source": [
                "class Tree:\r\n",
                "    def __init__ (self):\r\n",
                "        self.nodes = []\r\n",
                "    \r\n",
                "    def addNodes(self, nodeList, n, entVals, entities, dependencies):\r\n",
                "        if len(nodeList) == 3:\r\n",
                "            flag = 0\r\n",
                "            for i in range(3):\r\n",
                "                if nodeList[i] == \"<-\":\r\n",
                "                    self.nodes.append([nodeList[i], dependencies[n][0][0]])\r\n",
                "                if nodeList[i] == \"->\":\r\n",
                "                    self.nodes.append([nodeList[i], dependencies[n][0][1]])\r\n",
                "                else:\r\n",
                "                    ent = entVals[n][\"ENTITY\" + str(flag)]\r\n",
                "                    self.nodes.append([ent, \"NN\", \"NOUN\", entities[n][ent]])\r\n",
                "                    flag = 1\r\n",
                "        else:\r\n",
                "            relCount = 0\r\n",
                "            for i in range(len(nodeList)):\r\n",
                "                if (nodeList[i] == \"<-\"):\r\n",
                "                    self.nodes.append([nodeList[i], dependencies[n][relCount][0]])\r\n",
                "                    relCount += 1\r\n",
                "                elif ( nodeList[i] == \"->\"):\r\n",
                "                    self.nodes.append([nodeList[i], dependencies[n][relCount][1]])\r\n",
                "\r\n",
                "                # if (nodeList[i] == \"<-\" or nodeList[i] == \"->\"):\r\n",
                "                #     self.nodes.append([nodeList[i]])\r\n",
                "\r\n",
                "                # if (nodeList[i] == \"<-\" or nodeList[i] == \"->\"):\r\n",
                "                #     continue\r\n",
                "                \r\n",
                "                elif (nodeList[i] == \"entity0\"):\r\n",
                "                    ent = entVals[n][\"ENTITY0\"]\r\n",
                "                    self.nodes.append([ent, \"NN\", \"NOUN\", entities[n][ent]])\r\n",
                "                elif (nodeList[i] == \"entity1\"):\r\n",
                "                    ent = entVals[n][\"ENTITY1\"]\r\n",
                "                    self.nodes.append([ent, \"NN\", \"NOUN\", entities[n][ent]])\r\n",
                "                else:\r\n",
                "                    test = nlp(nodeList[i])\r\n",
                "                    for token in test:\r\n",
                "                        self.nodes.append([token.text, token.tag_, token.pos_])\r\n",
                "            \r\n",
                "    def displayNodes(self):\r\n",
                "        print(self.nodes)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "source": [
                "def similarityFunction(x, y):\r\n",
                "    if len(x) != len(y):\r\n",
                "        return 0\r\n",
                "    else:\r\n",
                "        simScore = 1\r\n",
                "        for (xVal, yVal) in zip(x, y):\r\n",
                "            tempSimScore = 0\r\n",
                "            if len(xVal) == len(yVal):\r\n",
                "                for i in range(len(xVal)):\r\n",
                "                    if isinstance(xVal[i], list):\r\n",
                "                        for j in xVal[i]:\r\n",
                "                            if j in yVal[i]:\r\n",
                "                                tempSimScore += 1\r\n",
                "                    elif xVal[i] == yVal[i]:\r\n",
                "                        tempSimScore += 1\r\n",
                "            simScore *= tempSimScore\r\n",
                "        return simScore\r\n",
                "\r\n",
                "def treeKernel(X1, X2):\r\n",
                "    gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))\r\n",
                "    for i, x1 in enumerate(X1):\r\n",
                "        for j, x2 in enumerate(X2):\r\n",
                "            gram_matrix[i, j] = similarityFunction(x1.nodes, x2.nodes)\r\n",
                "    return gram_matrix"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "source": [
                "nlp = spacy.load(\"en_ner_bionlp13cg_md\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "source": [
                "tree = ET.parse('data/train/train.xml')\r\n",
                "root = tree.getroot()\r\n",
                "print(root.tag)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "corpus\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "source": [
                "yLabel, docs, entVals, sentences, entities = dataPreprocess(root)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "source": [
                "print(len(docs), len(yLabel))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "17546 17546\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "source": [
                "entityLabels(sentences, entities)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "source": [
                "entities[6]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'ventral striatopallidal parts of the basal ganglia': ['BRAIN_REGION',\n",
                            "  'ORGANISM_SUBSTANCE',\n",
                            "  'CELLULAR_COMPONENT'],\n",
                            " 'subthalamic nucleus': ['BRAIN_REGION', 'ORGANISM_SUBSTANCE']}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 94
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "source": [
                "sentences[3260]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'Almost all of the prefrontal cortical projections to the hypothalamus arise from areas within the \"medial prefrontal network ,\" as defined previously by Carmichael and Price ([1996] J. Comp .'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 95
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "source": [
                "entities[3260]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'hypothalamus': ['BRAIN_REGION', 'ORGANISM_SUBDIVISION'],\n",
                            " 'medial prefrontal network': ['BRAIN_REGION', 'CELLULAR_COMPONENT']}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 96
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "source": [
                "for i in range(2):\r\n",
                "    shortestPaths, dependencies = shortestPathsCalculator(yLabel, docs, entVals, sentences, entities)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "17544 17544 17544 17545 17545 17545 17545 17545\n",
                        "17545 17545 17545 17545 17545 17545 17545 17545\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "source": [
                "for i in range(10):\r\n",
                "    print(docs[i])\r\n",
                "    print(shortestPaths[i], dependencies[i], yLabel[i])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "For this study , we examined the optic ( ENTITY0 , SO ), intermediate gray ( ENTITY1 , SGI ), intermediate white ( stratum album intermedium , SAI ), and deep gray ( stratum griseum profundum , SGP ) layers .\n",
                        "['entity0', '->', '(', '<-', 'entity1'] [['dep', 'punct'], ['punct', 'dep']] 0\n",
                        "For this study , we examined the optic ( ENTITY0 , SO ), intermediate gray ( stratum griseum intermedium , SGI ), intermediate white ( stratum album intermedium , SAI ), and deep gray ( ENTITY1 , SGP ) layers .\n",
                        "['entity0', '->', ',', '<-', 'entity1'] [['dep', 'punct'], ['punct', 'compound']] 0\n",
                        "For this study , we examined the optic ( stratum opticum , SO ), intermediate gray ( ENTITY0 , SGI ), intermediate white ( stratum album intermedium , SAI ), and deep gray ( ENTITY1 , SGP ) layers .\n",
                        "['entity0', '->', ',', '<-', 'entity1'] [['dep', 'punct'], ['punct', 'compound']] 0\n",
                        "For this study , we examined the optic ( ENTITY1 , SO ), intermediate gray ( stratum griseum intermedium , SGI ), intermediate white ( ENTITY0 , SAI ), and deep gray ( stratum griseum profundum , SGP ) layers .\n",
                        "['entity0', '<-', '(', '->', 'entity1'] [['punct', 'appos'], ['dep', 'punct']] 0\n",
                        "For this study , we examined the optic ( stratum opticum , SO ), intermediate gray ( ENTITY1 , SGI ), intermediate white ( ENTITY0 , SAI ), and deep gray ( stratum griseum profundum , SGP ) layers .\n",
                        "['entity0', '<-', '(', '->', 'entity1'] [['punct', 'dep'], ['dep', 'punct']] 0\n",
                        "For this study , we examined the optic ( stratum opticum , SO ), intermediate gray ( stratum griseum intermedium , SGI ), intermediate white ( ENTITY0 , SAI ), and deep gray ( ENTITY1 , SGP ) layers .\n",
                        "['entity0', '->', ',', '<-', 'entity1'] [['dep', 'punct'], ['punct', 'compound']] 0\n",
                        "Connections of the ENTITY1 with ENTITY0 in the rat .\n",
                        "['entity0', '->', 'connections', '<-', 'entity1'] [['ROOT', 'nmod'], ['nmod', 'ROOT']] 1\n",
                        "The present study was undertaken to establish the precise anatomical relationship of the ENTITY1 ( STh ) with ENTITY0 in the rat .\n",
                        "['entity0', '->', 'relationship', '<-', 'entity1'] [['dobj', 'nmod'], ['nmod', 'dobj']] 0\n",
                        "The results of these tracing experiments confirm the general notion of reciprocal connections between the ENTITY0 ( STh ) and ENTITY1 .\n",
                        "['entity0', '->', 'entity1'] [['nmod', 'conj']] 1\n",
                        "Thus the ENTITY0 ( STh ) is connected with the ENTITY1 , whereas a more ventral and lateral part of the medial subthalamic nucleus ( STh ) is related to the medial globus pallidus .\n",
                        "['entity0', '<-', 'connected', '->', 'entity1'] [['nsubjpass', 'ROOT'], ['ROOT', 'nmod']] 1\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "source": [
                "xObjects = []\r\n",
                "for i in range(len(shortestPaths)):\r\n",
                "    obj = Tree()\r\n",
                "    obj.addNodes(shortestPaths[i], i, entVals, entities, dependencies)\r\n",
                "    xObjects.append(obj)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "source": [
                "for i in range(10):\r\n",
                "    xObjects[i].displayNodes()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[['stratum opticum', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']], ['->', 'punct'], ['(', '-LRB-', 'PUNCT'], ['<-', 'dep'], ['stratum griseum intermedium', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']]]\n",
                        "[['stratum opticum', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']], ['->', 'punct'], [',', ',', 'PUNCT'], ['<-', 'dep'], ['stratum griseum profundum', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']]]\n",
                        "[['stratum griseum intermedium', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']], ['->', 'punct'], [',', ',', 'PUNCT'], ['<-', 'dep'], ['stratum griseum profundum', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']]]\n",
                        "[['stratum album intermedium', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']], ['<-', 'punct'], ['(', '-LRB-', 'PUNCT'], ['->', 'punct'], ['stratum opticum', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']]]\n",
                        "[['stratum album intermedium', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']], ['<-', 'punct'], ['(', '-LRB-', 'PUNCT'], ['->', 'punct'], ['stratum griseum intermedium', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']]]\n",
                        "[['stratum album intermedium', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']], ['->', 'punct'], [',', ',', 'PUNCT'], ['<-', 'dep'], ['stratum griseum profundum', 'NN', 'NOUN', ['BRAIN_REGION', 'IMMATERIAL_ANATOMICAL_ENTITY']]]\n",
                        "[['ventral striatopallidal parts of the basal ganglia', 'NN', 'NOUN', ['BRAIN_REGION', 'ORGANISM_SUBSTANCE', 'CELLULAR_COMPONENT']], ['->', 'nmod'], ['connections', 'NNS', 'NOUN'], ['<-', 'ROOT'], ['subthalamic nucleus', 'NN', 'NOUN', ['BRAIN_REGION', 'ORGANISM_SUBSTANCE']]]\n",
                        "[['limbic lobe - afferented parts of the basal ganglia', 'NN', 'NOUN', ['BRAIN_REGION', 'PATHOLOGICAL_FORMATION', 'CELLULAR_COMPONENT']], ['->', 'nmod'], ['relationship', 'NN', 'NOUN'], ['<-', 'dobj'], ['subthalamic nucleus', 'NN', 'NOUN', ['BRAIN_REGION', 'ORGANISM_SUBSTANCE']]]\n",
                        "[['subthalamic nucleus', 'NN', 'NOUN', ['BRAIN_REGION', 'ORGANISM_SUBSTANCE']], ['->', 'nmod', 'conj'], ['pallidal areas', 'NN', 'NOUN', ['BRAIN_REGION', 'ORGANISM_SUBSTANCE']]]\n",
                        "[['dorsomedial part of the subthalamic nucleus', 'NN', 'NOUN', ['BRAIN_REGION', 'SIMPLE_CHEMICAL', 'ORGANISM_SUBSTANCE']], ['<-', 'nsubjpass'], ['connected', 'VBN', 'VERB'], ['->', 'nmod'], ['subcommisural ventral pallidum', 'NN', 'NOUN', ['BRAIN_REGION', 'TISSUE']]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "source": [
                "xObjects = np.array(xObjects)\r\n",
                "yLabel = np.array(yLabel)\r\n",
                "print(len(xObjects), len(yLabel))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "17545 17545\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# VALIDATION AND OPTIMIZATION"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "source": [
                "def SVM(count, C):\r\n",
                "    print(str(count) + \":\" + str(C))\r\n",
                "    classifier = SVC(kernel = \"precomputed\", C = C)\r\n",
                "    model = classifier.fit(treeKernel(xObjectsTrain, xObjectsTrain), yLabelTrain)\r\n",
                "    pred = model.predict(treeKernel(xObjectsValid, xObjectsTrain))\r\n",
                "    results[count][0] = C\r\n",
                "    results[count][1] = model.score(treeKernel(xObjectsValid, xObjectsTrain), yLabelValid)\r\n",
                "    results[count][2] = f1_score(yLabelValid, pred)\r\n",
                "    results[count][3] = precision_score(yLabelValid, pred)\r\n",
                "    results[count][4] = recall_score(yLabelValid, pred)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "source": [
                "# xObjectsTrain = xObjects[:1800]\r\n",
                "# yLabelTrain = yLabel[:1800]\r\n",
                "# xObjectsValid = xObjects[1800:]\r\n",
                "# yLabelValid = yLabel[1800:]\r\n",
                "xObjectsArray = np.array_split(xObjects, 10)\r\n",
                "yLabelArray = np.array_split(yLabel, 10)\r\n",
                "fold = 0\r\n",
                "finalC = 0\r\n",
                "finalF1 = 0\r\n",
                "for z in range(10):\r\n",
                "    xObjectsValid = xObjectsArray[z]\r\n",
                "    yLabelValid = yLabelArray[z]\r\n",
                "    xObjectsTrain = np.array([])\r\n",
                "    yLabelTrain = np.array([])\r\n",
                "    for j in range(10):\r\n",
                "        if j == z:\r\n",
                "            continue\r\n",
                "        else:\r\n",
                "            xObjectsTrain = np.concatenate((xObjectsTrain, xObjectsArray[j]))\r\n",
                "            yLabelTrain = np.concatenate((yLabelTrain, yLabelArray[j]))\r\n",
                "    c = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1]\r\n",
                "    results = np.zeros((7, 5))\r\n",
                "    count = 0\r\n",
                "    for i in c:\r\n",
                "        # SVM(count, i)\r\n",
                "        classifier = SVC(kernel = \"precomputed\", C = i)\r\n",
                "        model = classifier.fit(treeKernel(xObjectsTrain, xObjectsTrain), yLabelTrain)\r\n",
                "        pred = model.predict(treeKernel(xObjectsValid, xObjectsTrain))\r\n",
                "        results[count][0] = i\r\n",
                "        results[count][1] = model.score(treeKernel(xObjectsValid, xObjectsTrain), yLabelValid)\r\n",
                "        results[count][2] = f1_score(yLabelValid, pred)\r\n",
                "        results[count][3] = precision_score(yLabelValid, pred)\r\n",
                "        results[count][4] = recall_score(yLabelValid, pred)\r\n",
                "        count += 1\r\n",
                "    bestC = 0\r\n",
                "    bestF1 = 0\r\n",
                "    for i in range(7):\r\n",
                "        if results[i][2] > bestF1:\r\n",
                "            bestC = results[i][0]\r\n",
                "            bestF1 = results[i][2]\r\n",
                "    if bestF1 > finalF1:\r\n",
                "        finalC = bestC\r\n",
                "        fold = z\r\n",
                "        finalF1 = bestF1\r\n",
                "    print(\"Fold: {}\\t\\tC: {}\\t\\tF1: {}\".format(z, bestC, bestF1))\r\n",
                "print(\"Best Fold: {}\\t\\tC: {}\\t\\tF1: {}\".format(fold, finalC, finalF1))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Fold: 0\t\tC: 0.05\t\tF1: 0.21666666666666665\n",
                        "Fold: 1\t\tC: 0.05\t\tF1: 0.24311926605504589\n",
                        "Fold: 2\t\tC: 0.05\t\tF1: 0.23255813953488372\n",
                        "Fold: 3\t\tC: 0.01\t\tF1: 0.1758957654723127\n",
                        "Fold: 4\t\tC: 0.05\t\tF1: 0.3026315789473684\n",
                        "Fold: 5\t\tC: 0.05\t\tF1: 0.2066869300911854\n",
                        "Fold: 6\t\tC: 0.05\t\tF1: 0.22594142259414227\n",
                        "Fold: 7\t\tC: 0.05\t\tF1: 0.2487046632124352\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14276/358174673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# SVM(count, i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"precomputed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreeKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxObjectsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxObjectsTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myLabelTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreeKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxObjectsValid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxObjectsTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14276/2215552390.py\u001b[0m in \u001b[0;36mtreeKernel\u001b[1;34m(X1, X2)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mgram_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarityFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgram_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Train Using Best Parameters"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "xObjectsValid = xObjectsArray[fold]\r\n",
                "yLabelValid = yLabelArray[fold]\r\n",
                "xObjectsTrain = np.array([])\r\n",
                "yLabelTrain = np.array([])\r\n",
                "for j in range(10):\r\n",
                "    if j == fold:\r\n",
                "        continue\r\n",
                "    else:\r\n",
                "        xObjectsTrain = np.concatenate((xObjectsTrain, xObjectsArray[j]))\r\n",
                "        yLabelTrain = np.concatenate((yLabelTrain, yLabelArray[j]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "classifier = SVC(kernel = \"precomputed\", C = finalC, gamma = \"scale\")\r\n",
                "model = classifier.fit(treeKernel(xObjectsTrain, xObjectsTrain), yLabelTrain)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Testing"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "treeTest = ET.parse('data/test/WhiteTextUnseenEval.xml')\r\n",
                "rootTest = treeTest.getroot()\r\n",
                "print(rootTest.tag)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "corpus\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "yLabelTest, docsTest, entValsTest, sentencesTest, entitiesTest = dataPreprocess(rootTest)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(len(docsTest), len(yLabelTest))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1028 1028\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "entityLabels(sentencesTest, entitiesTest)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "for i in range(2):\r\n",
                "    shortestPathsTest, dependenciesTest = shortestPathsCalculator(yLabelTest, docsTest, entValsTest, sentencesTest, entitiesTest)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1028 1028 1028 1028 1028 1028 1028 1028\n",
                        "1028 1028 1028 1028 1028 1028 1028 1028\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "xObjectsTest = []\r\n",
                "for i in range(len(shortestPathsTest)):\r\n",
                "    obj = Tree()\r\n",
                "    obj.addNodes(shortestPathsTest[i], i, entValsTest, entitiesTest, dependenciesTest)\r\n",
                "    xObjectsTest.append(obj)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "xObjectsTest = np.array(xObjectsTest)\r\n",
                "yLabelTest = np.array(yLabelTest)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "pred = model.predict(treeKernel(xObjectsTest, xObjectsTrain))\r\n",
                "accuracy = model.score(treeKernel(xObjectsTest, xObjectsTrain), yLabelTest)\r\n",
                "f1 = f1_score(yLabelTest, pred)\r\n",
                "f2 = fbeta_score(yLabelTest, pred, beta = 2)\r\n",
                "precision = precision_score(yLabelTest, pred)\r\n",
                "recall = recall_score(yLabelTest, pred)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(\"    Accuracy     F1     Precision    Recall     F2\")\r\n",
                "print(\"{:10.4f} {:10.4f} {:10.4f} {:10.4f}\".format(accuracy, f1, precision, recall, f2))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "    Accuracy     F1     Precision    Recall\n",
                        "    0.7354     0.5090     0.6157     0.4338\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit"
        },
        "interpreter": {
            "hash": "c627be1547c7c874688ddee1aaaa67b367275f1752d282bff5eb427acd241334"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}